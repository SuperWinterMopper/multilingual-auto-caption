@startuml
allowmixing

package Frontend {
    +class UI {

        +uploadVideo(): void
    }
}
Frontend.UI --> Backend.API

package Backend {
    +class API {
        +captionPipeline: CaptionPipeline

        +/upload(Video) 
        +/languages()
    }
    API --> CaptionPipeline

    Note right of API
        /upload Stores video locally, then calls CaptionPipeline.createCaptions()

        /languages returns what languages are available
    end Note

    +class CaptionPipeline {
        +preprocessor: VideoPreprocessor
        +VAD: VADModule
        +LID: LIDModule
        +ASR: ASRModule
        +encoder: CaptionEncoder

        +maxSegmentLength: int
        +minSegmentLength: int

        +languages: List[Models.Language]

        +createCaptions(videoPath: str): str //Main function of app, returns path to video path with video encoded
    }

    CaptionPipeline --> VideoPreprocessor
    CaptionPipeline --> VADModule
    CaptionPipeline --> LIDModule
    CaptionPipeline --> ASRModule
    CaptionPipeline --> CaptionEncoder

    +class VideoPreprocessor {
        +preprocessVideo(videoPath: str): str //returns path to audio file, preprocessed from video
    }

    +class VADModule {
        +findVoicedSegments(audioPath: str): List[VideoSegment]
    }
    ASRModule ..> VideoSegment

    +class LIDModule {
        +classifyLanguage(List[VideoSegment]): List[CaptionedVideoSegment]
    }
    LIDModule ..> CaptionedVideoSegment

    +class ASRModule {
        +fillSegmentText(List[CaptionedVideoSegment]): List[CaptionedVideoSegment]
    }
    ASRModule ..> CaptionedVideoSegment

    +class CaptionEncoder {
        +encodeVideoCaptions(videoPath: str, captions: List[CaptionedVideoSegment]): str //new video path
    }
    CaptionEncoder ..> CaptionedVideoSegment

    +interface VideoSegment {
        +start: float 
        +end: float
    }

    +interface CaptionedVideoSegment {
        +text: str
        +language: Models.Language
    }
    CaptionedVideoSegment --|> VideoSegment

}

Backend.VADModule --> Models.VAD
Backend.ASRModule --> Models.ASR
Backend.LIDModule --> Models.LID
Backend.CaptionPipeline --> Models.Language

package Models {
    +class VADPipeline {
        
    }
    +class LIDPipeline {

    }
    +class ASRPipeline {

    }
    +class Language {
        +name: str 
        +value: int
    }

    +abstract class ModelPipeline {
        +ModelPipelineTester: PipelineTester
        +ModelPipelineLogger: PipelineLogger

        +run_pipeline(collect_data: bool, preprocess_data: bool, split_data: bool, train: bool, evaluate: bool, save_model: bool): void
        -collect_data(): void
        -preprocess_data(): void
        -split_data(): void
        -train(): void
        -evaluate(): void
        -save_model(): void

        -fail(text: str): void
    }

    +abstract class PipelineLogger {
        +blog_collect_data(): void
        +blog_preprocess_data(): void
        +blog_split_data(): void
        +blog_train(): void
        +blog_evaluate(): void
        +blog_save_model(): void

        +alog_collect_data(): void
        +alog_preprocess_data(): void
        +alog_split_data(): void
        +alog_train(): void
        +alog_evaluate(): void
        +alog_save_model(): void
    }

    +abstract class PipelineTester {
        +btest_collect_data(): void 
        +btest_preprocess_data(): void
        +btest_split_data(): void
        +btest_train(): void
        +btest_evaluate(): void
        +btest_save_model(): void

        +atest_collect_data(): void
        +atest_preprocess_data(): void
        +atest_split_data(): void
        +atest_train(): void
        +atest_evaluate(): void
        +atest_save_model(): void
    }
}
Models.ModelPipeline --> Models.PipelineTester
Models.ModelPipeline --> Models.PipelineLogger

Models.PipelineTester ..> Models.ModelPipeline
Models.PipelineLogger ..> Models.ModelPipeline

@enduml